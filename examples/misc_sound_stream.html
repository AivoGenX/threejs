<!DOCTYPE html>
<html lang="en">
	<head>
		<title>three.js misc - sound stream</title>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0">
		<style>
			body {
				background:#777;
				padding:0;
				margin:0;
				font-weight: bold;
				overflow:hidden;
			}

			#info {
				position: absolute;
				top: 0px;
				width: 100%;
				color: #ffffff;
				padding: 5px;
				font-family:Monospace;
				font-size:13px;
				text-align:center;
			}

			a {
				color: #ffffff;
			}
		</style>

		<script src="../build/three.js"></script>
		<script src="js/Detector.js"></script>
		<script src="js/libs/stats.min.js"></script>

		<script id="vertexShader" type="x-shader/x-vertex">

			void main()	{

				gl_Position = vec4( position, 1.0 );

			}

		</script>

		<script id="fragmentShader" type="x-shader/x-fragment">

			uniform sampler2D tAudioData;
			uniform vec2 resolution;

			void main()	{

				vec2 uv = gl_FragCoord.xy / resolution.xy;

				vec3 backgroundColor = vec3( 0.0 );
				vec3 color = vec3( 1.0, 0.0, 0.0 );

				float f = texture2D( tAudioData, vec2( uv.x, 0 ) ).r; // sample data texture, only the red channel is relevant
				float i = step( uv.y, f );

				gl_FragColor = vec4( mix( backgroundColor, color, i ), 1.0 );

			}

		</script>

	</head>
<body>

	<div id="container"></div>
	<div id="info"><a href="https://threejs.org" target="_blank">three.js</a> - misc - sound stream</div>

	<script>

	if ( ! Detector.webgl ) Detector.addGetWebGLMessage();

	var scene, camera, renderer, analyser, uniforms;
	var container, stats;

	init();
	animate();

	function init() {

		var fftSize = 2048;

		// container

		container = document.getElementById( 'container' );

		// scene

		scene = new THREE.Scene();

		// renderer

		renderer = new THREE.WebGLRenderer( { antialias: true } );
		renderer.setSize( window.innerWidth, window.innerHeight );
		renderer.setClearColor( 0x20252f );
		renderer.setPixelRatio( window.devicePixelRatio );
		container.appendChild( renderer.domElement );

		// camera

		camera = new THREE.PerspectiveCamera( 45, window.innerWidth / window.innerHeight, 1, 1000 );
		camera.position.set( 0, 5, 50 );

		// audio listener

		var listener = new THREE.AudioListener();
		camera.add( listener );

		// audio stream and analyzer

		var audioStream = new THREE.AudioStream( 'sounds/358232_j_s_song.mp3', listener );
		audioStream.setLoop( true );
		analyser = new THREE.AudioAnalyser( audioStream, fftSize );

		audioStream.play();

		// geometry

		var geometry = new THREE.PlaneBufferGeometry( 2, 2 );

		// custom shader material

		var size = fftSize / 2;

		uniforms = {
			tAudioData: { value: new THREE.DataTexture( new Uint8Array( size * 3 ), size, 1, THREE.RGBFormat ) },
			resolution: { value: new THREE.Vector2( renderer.domElement.width, renderer.domElement.height ) }
		};

		var material = new THREE.ShaderMaterial( {

			uniforms: uniforms,
			vertexShader: document.getElementById( 'vertexShader' ).textContent,
			fragmentShader: document.getElementById( 'fragmentShader' ).textContent

		} );

		// mesh

		var mesh = new THREE.Mesh( geometry, material );
		scene.add( mesh );

		// stats.js

		stats = new Stats();
		container.appendChild( stats.dom );

		// event listener

		window.addEventListener( 'resize', onResize, false );

	}

	function onResize() {

		renderer.setSize( window.innerWidth, window.innerHeight );

		uniforms.resolution.value.x = renderer.domElement.width;
		uniforms.resolution.value.y = renderer.domElement.height;

	}

	function animate() {

		requestAnimationFrame( animate );

		render();
		stats.update();

	}

	function render() {

		var data = analyser.getFrequencyData();

		// transfer all frequency data to our data texture so we can use them in the fragment shader

		for ( var i = 0, l = data.length; i < l; i ++ ) {

			uniforms.tAudioData.value.image.data[ i * 3 ] = data[ i ];

		}

		uniforms.tAudioData.value.needsUpdate = true;

		renderer.render( scene, camera );

	}

	</script>

</body>
</html>
